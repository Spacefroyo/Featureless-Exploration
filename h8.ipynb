{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Similarity Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from scipy.sparse import csr_matrix\n",
    "import surprise\n",
    "from surprise import SVD, Reader, Dataset, accuracy, SVDpp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import math\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = [d for d in readJSON(\"train.json.gz\")]\n",
    "np.random.shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = {}\n",
    "gmap = {}\n",
    "\n",
    "for d in raw_data:\n",
    "    u, g = d['userID'], d['gameID']\n",
    "    if u not in umap:\n",
    "        umap[u] = len(umap)\n",
    "    if g not in gmap:\n",
    "        gmap[g] = len(gmap)\n",
    "\n",
    "    d['user'] = umap[u]\n",
    "    d['game'] = gmap[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    j = 0\n",
    "    ans = []\n",
    "    for i in range(len(lst1)):\n",
    "        while (j < len(lst2) and lst2[j] < lst1[i]):\n",
    "            j += 1\n",
    "        if j >= len(lst2):\n",
    "            break\n",
    "        if lst2[j] == lst1[i]:\n",
    "            ans.append(lst1[i])\n",
    "            j += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(lst1, lst2):\n",
    "    lst1 = set(lst1)\n",
    "    lst2 = set(lst2)\n",
    "    return len(lst1.intersection(lst2)) / (math.sqrt(len(lst1)) * math.sqrt(len(lst2)))\n",
    "\n",
    "def Jaccard(lst1, lst2):\n",
    "    lst1 = set(lst1)\n",
    "    lst2 = set(lst2)\n",
    "    return len(lst1.intersection(lst2)) / len(lst1.union(lst2))\n",
    "\n",
    "def Pearson(lst1, lst2):\n",
    "    lst1 = set(lst1)\n",
    "    lst2 = set(lst2)\n",
    "    return len(lst1.intersection(lst2)) / (len(lst1) * len(lst2))\n",
    "\n",
    "def ModJaccard(lst1, lst2):\n",
    "    lst1 = set(lst1)\n",
    "    lst2 = set(lst2)\n",
    "    return len(lst1.intersection(lst2)) / len(lst1.union(lst2).difference(lst1.intersection(lst2)))\n",
    "\n",
    "def LopJaccard(lst1, lst2):\n",
    "    lst1 = set(lst1)\n",
    "    lst2 = set(lst2)\n",
    "    return len(lst1.intersection(lst2)) / len(lst1)\n",
    "\n",
    "def Custom(i, j, lst1, lst2):\n",
    "    sim = 0\n",
    "    for u in intersection(lst1, lst2):\n",
    "        sim += (interactions[(u,i)] + interactions[(u,j)]) / (1+np.abs(interactions[(u,i)] - interactions[(u,j)])) / 28\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(d['user'], d['game'], d['hours_transformed']) for d in raw_data]\n",
    "\n",
    "interactions = {}\n",
    "gamesPerUser = defaultdict(set)\n",
    "usersPerGame = defaultdict(set)\n",
    "sim_ij = defaultdict(int)\n",
    "\n",
    "def sim(i, j, func=Custom):\n",
    "    if (i, j) in sim_ij:\n",
    "        return sim_ij[(i, j)]\n",
    "    \n",
    "    users_i = usersPerGame[i]\n",
    "    users_j = usersPerGame[j]\n",
    "    if func == Custom:\n",
    "        sim_ij[(i, j)] = func(i, j, users_i, users_j)\n",
    "        sim_ij[(j, i)] = func(i, j, users_j, users_i)\n",
    "    else:\n",
    "        sim_ij[(i, j)] = func(users_i, users_j)\n",
    "        sim_ij[(j, i)] = func(users_j, users_i)\n",
    "    return sim_ij[(i, j)]\n",
    "\n",
    "def train(dataset):\n",
    "    global interactions, gamesPerUser, usersPerGame\n",
    "    \n",
    "    interactions = {}\n",
    "    gamesPerUser = defaultdict(list)\n",
    "    usersPerGame = defaultdict(list)\n",
    "    \n",
    "    for d in dataset:\n",
    "        u, g, h = d\n",
    "        interactions[(u,g)] = h\n",
    "        gamesPerUser[u].append(g)\n",
    "        usersPerGame[g].append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = train_test_split(dataset, test_size=0.1, shuffle=False)\n",
    "\n",
    "models = train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hours = np.mean([d[2] for d in dataset])\n",
    "hoursPerGame = defaultdict(lambda: mean_hours)\n",
    "for g in usersPerGame:\n",
    "    hoursPerGame[g] = np.mean([interactions[(u,g)] for u in usersPerGame[g]])\n",
    "    if (hoursPerGame[g] == 0):\n",
    "        hoursPerGame[g] = mean_hours\n",
    "\n",
    "hoursPerUser = defaultdict(lambda: mean_hours)\n",
    "for u in gamesPerUser:\n",
    "    hoursPerUser[u] = np.mean([interactions[(u,g)] for g in gamesPerUser[u]])\n",
    "    if (hoursPerUser[u] == 0):\n",
    "        hoursPerUser[u] = mean_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(u, i, func=Custom):\n",
    "    if len(gamesPerUser[u]) == 0:\n",
    "        return hoursPerGame[i]\n",
    "    return hoursPerGame[i] + 1 / len(gamesPerUser[u]) * sum([sim(i, j, func) * (interactions[(u, j)] - hoursPerGame[j]) for j in gamesPerUser[u] if j != i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine 3.18850048322312\n",
      "Jaccard 3.1968137372184953\n",
      "Pearson 3.2035744804366897\n",
      "ModJaccard 3.1966175110417834\n",
      "LopJaccard 3.1854065150428927\n",
      "Custom 3.202601772422115\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for func in [Cosine, Jaccard, Pearson, ModJaccard, LopJaccard, Custom]:\n",
    "    sim_ij = defaultdict(int)\n",
    "    prediction = [predict(u, i, func) for (u, i, h) in validset]\n",
    "    MSE = mean_squared_error(prediction, [h for (u,g,h) in validset])\n",
    "    print(func.__name__, MSE)\n",
    "\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from scipy.sparse import csr_matrix\n",
    "import surprise\n",
    "from surprise import SVD, Reader, Dataset, accuracy, SVDpp, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, BaselineOnly, CoClustering\n",
    "from surprise.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import math\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "otasks = []\n",
    "header = \"\"\n",
    "\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        header = l\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    if u not in umap:\n",
    "        umap[u] = len(umap)\n",
    "    if g not in gmap:\n",
    "        gmap[g] = len(gmap)\n",
    "    otasks.append((u,g))\n",
    "    u = umap[u]\n",
    "    g = gmap[g]\n",
    "    tasks.append((u,g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(d['user'], d['game'], d['hours_transformed']) for d in raw_data]\n",
    "df = pd.DataFrame(dataset, columns =['user', 'game', 'hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 14.013750114071462\n"
     ]
    }
   ],
   "source": [
    "print(df['hours'].min(), df['hours'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(df['hours'].min(), df['hours'].max()))\n",
    "data = Dataset.load_from_df(df[[\"user\", \"game\", \"hours\"]], reader)\n",
    "\n",
    "train, valid = train_test_split(data, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factors = [2, 3, 5, 10, 15, 20, 25]\n",
    "# for factor in factors:\n",
    "#     param_grid = {\"n_epochs\": [5, 10, 20, 50], \"reg_all\": [0.01, 0.05, 0.1, 0.2], \"n_factors\": [factor]}\n",
    "#     gs = GridSearchCV(SVD, param_grid, measures=[\"mse\"], cv=5)\n",
    "\n",
    "#     gs.fit(data)\n",
    "\n",
    "#     print(factor, gs.best_score[\"mse\"], gs.best_params[\"mse\"])\n",
    "\n",
    "# 2 3.0879222970713043 {'n_epochs': 20, 'reg_all': 0.1, 'n_factors': 2}\n",
    "# 3 3.086121620599191 {'n_epochs': 20, 'reg_all': 0.1, 'n_factors': 3}\n",
    "# 5 3.087488467139108 {'n_epochs': 10, 'reg_all': 0.01, 'n_factors': 5}\n",
    "# 10 3.100085170101152 {'n_epochs': 10, 'reg_all': 0.05, 'n_factors': 10}\n",
    "# 15 3.101539947261756 {'n_epochs': 10, 'reg_all': 0.05, 'n_factors': 15}\n",
    "# 20 3.106343392649928 {'n_epochs': 10, 'reg_all': 0.05, 'n_factors': 20}\n",
    "# 25 3.1076779148589075 {'n_epochs': 10, 'reg_all': 0.05, 'n_factors': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "params = [(20, 0.1, 2), (20, 0.1, 3), (10, 0.01, 5), (10, 0.05, 10), (10, 0.05, 15), (10, 0.05, 20), (10, 0.05, 25)]\n",
    "copies = 3\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(copies):\n",
    "    for param in params:\n",
    "        model = SVD(n_epochs=param[0], reg_all=param[1], n_factors=param[2])\n",
    "        model.fit(train)\n",
    "        models.append(model)\n",
    "\n",
    "        model = SVDpp(n_epochs=param[0], reg_all=param[1], n_factors=param[2])\n",
    "        model.fit(train)\n",
    "        models.append(model)\n",
    "\n",
    "        model = KNNBasic(k=i*10)\n",
    "        model.fit(train)\n",
    "        models.append(model)\n",
    "\n",
    "        model = KNNWithMeans(k=i*10)\n",
    "        model.fit(train)\n",
    "        models.append(model)\n",
    "\n",
    "        model = KNNWithZScore(k=i*10)\n",
    "        model.fit(train)\n",
    "        models.append(model)\n",
    "\n",
    "        model = KNNBaseline(k=i*10)\n",
    "        model.fit(train)\n",
    "        models.append(model)\n",
    "\n",
    "        model = BaselineOnly()\n",
    "    model.fit(train)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    output = model.test(valid)\n",
    "    predictions.append([o.est for o in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE:  3.1211926658236915\n"
     ]
    }
   ],
   "source": [
    "mean_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "mean_MSE = mean_squared_error([o.r_ui for o in output], mean_pred)\n",
    "print(\"Mean MSE: \", mean_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed MSE:  2.993156192014606\n"
     ]
    }
   ],
   "source": [
    "X = np.array(predictions).T\n",
    "y = [o.r_ui for o in output]\n",
    "\n",
    "mixer = Ridge()\n",
    "mixer.fit(X, y)\n",
    "\n",
    "valid_pred = mixer.predict(X)\n",
    "valid_MSE = mean_squared_error(y, valid_pred)\n",
    "print(\"Mixed MSE: \", valid_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misses = []\n",
    "# for i, pred in enumerate(valid_pred):\n",
    "#     if abs(valid[i][2] - pred) > 3:\n",
    "#         misses.append((*valid[i], pred))\n",
    "# misses.sort(key=lambda x: -abs(x[2] - x[3]))\n",
    "# print(misses[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for func in [Cosine, Jaccard, Pearson, ModJaccard, LopJaccard, Custom]:\n",
    "    sim_ij = defaultdict(int)\n",
    "    prediction = [predict(u, i, func) for (u, i) in tasks]\n",
    "\n",
    "    test_predictions.append(prediction)\n",
    "\n",
    "for model in models:\n",
    "    test_prediction = []\n",
    "    for task in tasks:\n",
    "        u, g = task\n",
    "        test_prediction.append(model.predict(u, g).est)\n",
    "    test_predictions.append(test_prediction)\n",
    "\n",
    "test_predictions = np.array(test_predictions).T\n",
    "test_pred = mixer.predict(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "predictions.write(header)\n",
    "for i in range(len(tasks)):\n",
    "    u,g = otasks[i]\n",
    "    predictions.write(u + ',' + g + \",\" + str(test_pred[i]) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

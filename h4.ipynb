{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from scipy.sparse import csr_matrix\n",
    "import surprise\n",
    "from surprise import SVD, Reader, Dataset, accuracy, SVDpp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = [d for d in readJSON(\"train.json.gz\")]\n",
    "np.random.shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = {}\n",
    "gmap = {}\n",
    "\n",
    "for d in raw_data:\n",
    "    u, g = d['userID'], d['gameID']\n",
    "    if u not in umap:\n",
    "        umap[u] = len(umap)\n",
    "    if g not in gmap:\n",
    "        gmap[g] = len(gmap)\n",
    "\n",
    "    d['user'] = umap[u]\n",
    "    d['game'] = gmap[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "header = \"\"\n",
    "\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        header = l\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    if u not in umap:\n",
    "        umap[u] = len(umap)\n",
    "    if g not in gmap:\n",
    "        gmap[g] = len(gmap)\n",
    "    u = umap[u]\n",
    "    g = gmap[g]\n",
    "    tasks.append((u,g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    j = 0\n",
    "    ans = []\n",
    "    for i in range(len(lst1)):\n",
    "        while (j < len(lst2) and lst2[j] < lst1[i]):\n",
    "            j += 1\n",
    "        if j >= len(lst2):\n",
    "            break\n",
    "        if lst2[j] == lst1[i]:\n",
    "            ans.append(lst1[i])\n",
    "            j += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(d['user'], d['game'], d['hours_transformed']) for d in raw_data]\n",
    "trainset, validset = train_test_split(dataset, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hours = np.mean([d[2] for d in dataset]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, Ku, Ki, lamb, layers, gammaU=None, gammaI=None):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(umap)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(gmap)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(umap),Ku],stddev=0.001) if gammaU is None else gammaU)\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(gmap),Ki],stddev=0.001) if gammaI is None else gammaI)\n",
    "        self.Ku = gammaU.shape[1]\n",
    "        self.Ki = gammaI.shape[1]\n",
    "        self.lamb = lamb\n",
    "\n",
    "        layers = [2+self.Ku+self.Ki] + layers + [1]\n",
    "        self.ffs = []\n",
    "        for i in range(len(layers)-1):\n",
    "            self.ffs.append(tf.Variable(tf.random.normal([1+layers[i],layers[i+1]],stddev=0.001)))\n",
    "\n",
    "    # Similarity between user and item latent factors\n",
    "    def sim(self, u, i):\n",
    "        # return tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        dp = [tf.tensordot(self.gammaU[u], self.gammaI[i], 1) if self.Ku == self.Ki else np.zeros([1])]\n",
    "        dst = [tf.norm(self.gammaU[u] - self.gammaI[i]) if self.Ku == self.Ki else np.zeros([1])]\n",
    "        x = tf.concat([dp, dst, self.gammaU[u], self.gammaI[i]], 0)\n",
    "        # x.assign(tf.reshape(x, [1,-1]))\n",
    "        for layer in self.ffs:\n",
    "            x = tf.concat([tf.ones([1]), x], 0)\n",
    "            x = tf.nn.relu(tf.tensordot(layer, x, 1))\n",
    "        return x\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i] +\\\n",
    "            self.sim(u, i)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2) +\\\n",
    "                            tf.reduce_sum(self.gammaU**2) +\\\n",
    "                            tf.reduce_sum(self.gammaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        dp = tf.reduce_sum(gamma_u * gamma_i, 1, keepdims=True) if self.Ku == self.Ki else np.zeros([len(sampleU),1])\n",
    "        dst = tf.norm(gamma_u - gamma_i, axis=1, keepdims=True) if self.Ku == self.Ki else np.zeros([len(sampleU),1])\n",
    "        x = tf.concat([dp, dst, gamma_u, gamma_i], 1)\n",
    "        for layer in self.ffs:\n",
    "            x = tf.concat([tf.ones([len(sampleU),1]), x], 1)\n",
    "            x = tf.nn.relu(tf.matmul(x, layer))\n",
    "        pred = self.alpha + beta_u + beta_i +\\\n",
    "               tf.reshape(x, [-1])\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammaU = np.zeros([len(umap), len(gmap)], dtype=np.float32)\n",
    "gammaI = np.zeros([len(gmap), len(umap)], dtype=np.float32)\n",
    "for d in dataset:\n",
    "    hours = d[2]\n",
    "    gammaU[d[0],d[1]] = hours\n",
    "    gammaI[d[1],d[0]] = hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(0.01)\n",
    "layers = [32, 32, 16]\n",
    "layers = [16, 16]\n",
    "layers = [64, 64]\n",
    "layers = [256, 256, 128]\n",
    "modelLFM = LatentFactorModel(mean_hours, 32, 32, 0.0001, layers, gammaU=gammaU, gammaI=gammaI)\n",
    "modelLFM.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStep(model, trainset):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,g,r = random.choice(trainset)\n",
    "            sampleU.append(u)\n",
    "            sampleI.append(g)\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validU, validI, validR = [], [], []\n",
    "for u,g,r in validset:\n",
    "    validU.append(u)\n",
    "    validI.append(g)\n",
    "    validR.append(r)\n",
    "\n",
    "def MSE(model):\n",
    "    predictions = model.predictSample(validU, validI).numpy()\n",
    "    MSE = mean_squared_error(validR, predictions)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, valid MSE =  5.0794759559495635\n",
      "iteration 20, valid MSE =  4.845770702433857\n",
      "iteration 30, valid MSE =  4.646609819891311\n",
      "iteration 40, valid MSE =  4.477126168145637\n",
      "iteration 50, valid MSE =  4.334492923516461\n",
      "iteration 60, valid MSE =  4.214443509126016\n",
      "iteration 70, valid MSE =  4.111781991581383\n",
      "iteration 80, valid MSE =  4.022071921523742\n",
      "iteration 90, valid MSE =  3.9443659764013512\n",
      "iteration 100, valid MSE =  3.877528145284004\n",
      "iteration 110, valid MSE =  3.81853238340689\n",
      "iteration 120, valid MSE =  3.765785383595601\n",
      "iteration 130, valid MSE =  3.7194293886652945\n",
      "iteration 140, valid MSE =  3.6778717861417833\n",
      "iteration 150, valid MSE =  3.6409208857623683\n",
      "iteration 160, valid MSE =  3.6080005768859698\n",
      "iteration 170, valid MSE =  3.5780493116200236\n",
      "iteration 180, valid MSE =  3.550144788190334\n",
      "iteration 190, valid MSE =  3.524779457328636\n",
      "iteration 200, valid MSE =  3.5024265364917797\n",
      "iteration 210, valid MSE =  3.482304660639027\n",
      "iteration 220, valid MSE =  3.4648496494113856\n",
      "iteration 230, valid MSE =  3.447794575628276\n",
      "iteration 240, valid MSE =  3.432221618257992\n",
      "iteration 250, valid MSE =  3.4185236092839313\n",
      "iteration 260, valid MSE =  3.405599608357945\n",
      "iteration 270, valid MSE =  3.3933619008262363\n",
      "iteration 280, valid MSE =  3.3822993521475917\n",
      "iteration 290, valid MSE =  3.3719605106326402\n",
      "iteration 300, valid MSE =  3.3624372586606066\n",
      "iteration 310, valid MSE =  3.352495675849305\n",
      "iteration 320, valid MSE =  3.3435494143229625\n",
      "iteration 330, valid MSE =  3.3369849117335666\n",
      "iteration 340, valid MSE =  3.3307628248152383\n",
      "iteration 350, valid MSE =  3.3247856341235504\n",
      "iteration 360, valid MSE =  3.3197135709052836\n",
      "iteration 370, valid MSE =  3.314723333205914\n",
      "iteration 380, valid MSE =  3.309587908336854\n",
      "iteration 390, valid MSE =  3.3046633822530675\n",
      "iteration 400, valid MSE =  3.2998125396950475\n",
      "iteration 410, valid MSE =  3.29512332734625\n",
      "iteration 420, valid MSE =  3.291297409203314\n",
      "iteration 430, valid MSE =  3.287769244984416\n",
      "iteration 440, valid MSE =  3.2845780066358703\n",
      "iteration 450, valid MSE =  3.2812650108422146\n",
      "iteration 460, valid MSE =  3.2779500094315033\n",
      "iteration 470, valid MSE =  3.2748711209525148\n",
      "iteration 480, valid MSE =  3.2720502102091507\n",
      "iteration 490, valid MSE =  3.2691428408935588\n",
      "iteration 500, valid MSE =  3.2661287332468274\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/petergao/Desktop/cse158/assignment1/h4.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prevMSE \u001b[39m=\u001b[39m MSE(modelLFM)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     obj \u001b[39m=\u001b[39m trainingStep(modelLFM, trainset)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     valid_MSE \u001b[39m=\u001b[39m MSE(modelLFM)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m9\u001b[39m): \n",
      "\u001b[1;32m/Users/petergao/Desktop/cse158/assignment1/h4.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         sampleI\u001b[39m.\u001b[39mappend(g)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         sampleR\u001b[39m.\u001b[39mappend(r)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss \u001b[39m=\u001b[39m model(sampleU,sampleI,sampleR)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mreg()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergao/Desktop/cse158/assignment1/h4.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, model\u001b[39m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/keras/src/engine/training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    567\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/keras/src/engine/base_layer.py:1075\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[39m# Accept NumPy and scalar inputs by converting to Tensors.\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1072\u001b[0m     \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mTensor, np\u001b[39m.\u001b[39mndarray, \u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m))\n\u001b[1;32m   1073\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m input_list\n\u001b[1;32m   1074\u001b[0m ):\n\u001b[0;32m-> 1075\u001b[0m     inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m   1076\u001b[0m         _convert_numpy_or_python_types, inputs\n\u001b[1;32m   1077\u001b[0m     )\n\u001b[1;32m   1078\u001b[0m     input_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Handle `mask` propagation from previous layer to current layer. Masks\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39m# can be propagated explicitly via the `mask` argument, or implicitly\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m \u001b[39m# via setting the `_keras_mask` attribute on the inputs to a Layer.\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m \u001b[39m# Masks passed explicitly take priority.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.map_structure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure\u001b[39m(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    625\u001b[0m       nest_util\u001b[39m.\u001b[39;49mModality\u001b[39m.\u001b[39;49mCORE, func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    626\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[39m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[39m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[39mif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1055\u001b[0m \u001b[39melif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/keras/src/engine/base_layer.py:3755\u001b[0m, in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3753\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_numpy_or_python_types\u001b[39m(x):\n\u001b[1;32m   3754\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mTensor, np\u001b[39m.\u001b[39mndarray, \u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m)):\n\u001b[0;32m-> 3755\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(x)\n\u001b[1;32m   3756\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:140\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_traceback_filtering_enabled():\n\u001b[1;32m    141\u001b[0m       \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    142\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39m# In some very rare cases,\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# `is_traceback_filtering_enabled` (from the outer scope) may not be\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39m# accessible from inside this function\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:47\u001b[0m, in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdebugging.is_traceback_filtering_enabled\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_traceback_filtering_enabled\u001b[39m():\n\u001b[1;32m     34\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Check whether traceback filtering is currently enabled.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[39m  See also `tf.debugging.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m    was called).\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(_ENABLE_TRACEBACK_FILTERING, \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     48\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prevMSE = MSE(modelLFM)\n",
    "for i in range(1000):\n",
    "    obj = trainingStep(modelLFM, trainset)\n",
    "    valid_MSE = MSE(modelLFM)\n",
    "    if (i % 10 == 9): \n",
    "        print(\"iteration \" + str(i+1) + \", valid MSE = \", valid_MSE)\n",
    "    if valid_MSE > prevMSE:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

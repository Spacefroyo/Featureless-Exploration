{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from scipy.sparse import csr_matrix\n",
    "import surprise\n",
    "from surprise import SVD, Reader, Dataset, accuracy, SVDpp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import math\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = [d for d in readJSON(\"train.json.gz\")]\n",
    "np.random.shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = {}\n",
    "gmap = {}\n",
    "\n",
    "for d in raw_data:\n",
    "    u, g = d['userID'], d['gameID']\n",
    "    if u not in umap:\n",
    "        umap[u] = len(umap)\n",
    "    if g not in gmap:\n",
    "        gmap[g] = len(gmap)\n",
    "\n",
    "    d['user'] = umap[u]\n",
    "    d['game'] = gmap[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    j = 0\n",
    "    ans = []\n",
    "    for i in range(len(lst1)):\n",
    "        while (j < len(lst2) and lst2[j] < lst1[i]):\n",
    "            j += 1\n",
    "        if j >= len(lst2):\n",
    "            break\n",
    "        if lst2[j] == lst1[i]:\n",
    "            ans.append(lst1[i])\n",
    "            j += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(d['user'], d['game'], d['hours_transformed']) for d in raw_data]\n",
    "\n",
    "interactions = {}\n",
    "gamesPerUser = defaultdict(set)\n",
    "usersPerGame = defaultdict(set)\n",
    "usersPerUser = defaultdict(list)\n",
    "fits = {}\n",
    "\n",
    "def train(dataset) -> {int:Ridge}:\n",
    "    global interactions, gamesPerUser, usersPerGame, fits, usersPerUser\n",
    "    \n",
    "    interactions = defaultdict(int)\n",
    "    gamesPerUser = defaultdict(list)\n",
    "    usersPerGame = defaultdict(list)\n",
    "    usersPerUser = defaultdict(list)\n",
    "    fits = {}\n",
    "    \n",
    "    for d in dataset:\n",
    "        u, g, h = d\n",
    "        interactions[(u,g)] = h\n",
    "        gamesPerUser[u].append(g)\n",
    "        usersPerGame[g].append(u)\n",
    "\n",
    "    for u1 in gamesPerUser:\n",
    "        for u2 in gamesPerUser:\n",
    "            if u1 == u2: continue\n",
    "            gamesPerUser1 = gamesPerUser[u1]\n",
    "            gamesPerUser2 = gamesPerUser[u2]\n",
    "            sim = len(intersection(gamesPerUser1, gamesPerUser2))\n",
    "            if sim > 5:\n",
    "                usersPerUser[u1].append(u2)\n",
    "\n",
    "    models = {}\n",
    "    for u1 in usersPerUser:\n",
    "        models[u1] = Ridge(alpha=10)\n",
    "        X = [[interactions[(u2,g)] for u2 in usersPerUser[u1]] + [interactions[(u2,g)]**2 for u2 in usersPerUser[u1]] for g in gamesPerUser[u]]\n",
    "        y = [interactions[(u1,g)] for g in gamesPerUser[u]]\n",
    "        models[u1].fit(X, y)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "models = train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hours = np.mean([d[2] for d in dataset])\n",
    "hoursPerGame = defaultdict(lambda: mean_hours)\n",
    "for g in usersPerGame:\n",
    "    hoursPerGame[g] = np.mean([interactions[(u,g)] for u in usersPerGame[g]])\n",
    "    if (hoursPerGame[g] == 0):\n",
    "        hoursPerGame[g] = mean_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2893757638192076\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for (u,g,h) in validset:\n",
    "    if u in models:\n",
    "        predictions.append(models[u].predict([[interactions[(u2,g)] for u2 in usersPerUser[u]] + [interactions[(u2,g)]**2 for u2 in usersPerUser[u]]])[0])\n",
    "    else:\n",
    "        predictions.append(hoursPerGame[g])\n",
    "\n",
    "MSE = mean_squared_error(predictions, [h for (u,g,h) in validset])\n",
    "print(MSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
